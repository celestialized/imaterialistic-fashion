{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"markdown","source":"I find some data leakage from the validation set. Though I am not sure whether it is intentional for it being called 'validation' set. I am actually not sure about the validation set purpose."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import time\nscript_start_time = time.time()\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport gc\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport plotly.plotly as py\nimport cufflinks as cf\ncf.set_config_file(offline=True, world_readable=True, theme='ggplot')\nplt.rcParams[\"figure.figsize\"] = 12,8\nsns.set(rc={'figure.figsize':(20,12)})\nplt.style.use('fivethirtyeight')\n\npd.set_option('display.max_rows', 600)\npd.set_option('display.max_columns', 50)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Data path\ndata_path = '../input/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b71624737b094f61d08a636414e77de6ea073c0"},"cell_type":"markdown","source":"### 1. Load Data\nReference: [](https://www.kaggle.com/badalgupta/simple-data-exploration)"},{"metadata":{"trusted":true,"_uuid":"d3ce804f50e9450a193650e617541631da67abe7"},"cell_type":"code","source":"# 1. Load data =================================================================\nprint('%0.2f min: Start loading data'%((time.time() - script_start_time)/60))\ntrain={}\ntest={}\nvalidation={}\nwith open('%s/train.json'%(data_path)) as json_data:\n    train= json.load(json_data)\nwith open('%s/test.json'%(data_path)) as json_data:\n    test= json.load(json_data)\nwith open('%s/validation.json'%(data_path)) as json_data:\n    validation = json.load(json_data)\n\nprint('Train No. of images: %d'%(len(train['images'])))\nprint('Test No. of images: %d'%(len(test['images'])))\nprint('Validation No. of images: %d'%(len(validation['images'])))\n\n# JSON TO PANDAS DATAFRAME\n# train data\ntrain_img_url=train['images']\ntrain_img_url=pd.DataFrame(train_img_url)\ntrain_ann=train['annotations']\ntrain_ann=pd.DataFrame(train_ann)\ntrain=pd.merge(train_img_url, train_ann, on='imageId', how='inner')\n\n# test data\ntest=pd.DataFrame(test['images'])\n\n# Validation Data\nval_img_url=validation['images']\nval_img_url=pd.DataFrame(val_img_url)\nval_ann=validation['annotations']\nval_ann=pd.DataFrame(val_ann)\nvalidation=pd.merge(val_img_url, val_ann, on='imageId', how='inner')\n\ndel (train_img_url, train_ann, val_img_url, val_ann)\ngc.collect()\n\nprint('%0.2f min: Finish loading data'%((time.time() - script_start_time)/60))\nprint('='*50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f7a8ca33d5d584a99ea623a3df5c59ed65f17ee"},"cell_type":"markdown","source":"### 2. Check Data for Missing or Duplicated Values\nFindings:\na. No missing values\nb. No duplicates in each data set, but val urls are from test.\n"},{"metadata":{"trusted":true,"_uuid":"84885b31648270bace3eeab62f8d1deb0fe755e9"},"cell_type":"code","source":"datas = {'Train': train, 'Test': test, 'Validation': validation}\n\ntotal_url = []\ndataset_url = {}\nfor data_name, data in datas.items():\n    print('%s shape: %s'%(data_name, str(data.shape)))\n    print('%s Unique imageId: %s'%(data_name, len(data['imageId'].unique())))\n    print('%s Unique url: %s'%(data_name, len(data['url'].unique())))\n    print('%s NA: '%(data_name)) # No missing values\n    print(data.isnull().sum()) # No missing values\n    print('%s total unique url: %d'%(data_name, len(set(data['url'].tolist()))))\n    total_url = total_url + data['url'].tolist()\n    dataset_url[data_name] = data['url'].tolist()\n\n    print('-'*50)\n\n\nprint('Total images: %d'%(len(total_url)))\nprint('Total unique images: %d'%(len(set(total_url))))\nprint('Duplicated url: %d'%(len(total_url) - len(set(total_url))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fddf812105b69112fef7833b09b596a675684dd"},"cell_type":"markdown","source":"9897? A bit familiar? Yes, same as the number of val rows. \nStill, let's create a grid to search for the duplicated the url"},{"metadata":{"trusted":true,"_uuid":"3915a5f028261a310e21b5be5169de8e5d0f0215"},"cell_type":"code","source":"# Find the duplicated url\nfrom itertools import product\ncombinations = list(product(*[datas.keys(), datas.keys()]))\nfor comb in combinations:\n    print('%s inter %s: %d | %d'%(comb[0], comb[1], len(set(dataset_url[comb[0]])), len(set(dataset_url[comb[0]]).intersection(set(dataset_url[comb[1]])))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53e07125e5945ff754b1e2de42c5fb7ca6151f78"},"cell_type":"markdown","source":"'Test inter Validation: 39706 | 9897'\nWhat? Val is part of test?\nLet's confirm the duplicated url by merging test and val on url"},{"metadata":{"trusted":true,"_uuid":"2c1a5a03494cfb71de18c276be9c731f83c719bc"},"cell_type":"code","source":"# Confirm the duplicated url\ntest[['url']].merge(validation[['url']], how = 'inner').shape\ntest_ = test.merge(validation[['url', 'labelId']], on = 'url',how = 'left')\nprint('%s NA: '%('Test')) # No missing values\nprint(test_.isnull().sum() / test_.isnull().count())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"295e4283f0c076cca2dac5f8d148d91a338d05ae"},"cell_type":"markdown","source":"Let's which part of test are leaked"},{"metadata":{"trusted":true,"_uuid":"e4ce0e6344b82999940ae4a2c2e86145bd4f9845"},"cell_type":"code","source":"# Plot imageId of of leaked lable\ntest_leaked_lableId = test_[~pd.isna(test_['labelId'])]\ntest_unleaked_lableId = test_[pd.isna(test_['labelId'])]\nnumber_of_known_lableId = validation.shape[0]\nplt.plot(test_leaked_lableId['imageId'], '.')\nplt.plot(test_unleaked_lableId['imageId'], '.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fb473aa20f4e8bb603a31a43667f93b97008b2a"},"cell_type":"markdown","source":"Display images to confirm again the leakage"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"da32f54e00b5c27e426db6aca81971342a72b52b"},"cell_type":"code","source":"from IPython.display import Image\nfrom IPython.core.display import HTML\n\ndef display_category(urls, category_name):\n    img_style = \"width: 180px; margin: 0px; float: left; border: 1px solid black;\"\n    images_list = ''.join([f\"<img style='{img_style}' src='{u}' />\" for _, u in urls.head(12).iteritems()])\n    display(HTML(images_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ed6e017a26fb7b5e715a3bf1fc52fd99eb7f397"},"cell_type":"code","source":"#test data Images\nurls = test['url'][1:5]\ndisplay_category(urls, \"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd26ce25803a6ffc960214c4ef13214806749c5e"},"cell_type":"code","source":"#validation Images\nurls = validation['url'][1:5]\ndisplay_category(urls, \"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0c0b42f9f8e427836f1c214024c515617752def"},"cell_type":"code","source":"#train_data Images\nurls = train['url'][1:5]\ndisplay_category(urls, \"\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36d9ea74ef5ed33ac644a0932dff09958397dd64"},"cell_type":"markdown","source":"Now, we are 100% sure that the first 9897 of test set has their label id in val."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}