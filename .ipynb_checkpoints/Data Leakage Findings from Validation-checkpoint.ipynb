{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "I find some data leakage from the validation set. Though I am not sure whether it is intentional for it being called 'validation' set. I am actually not sure about the validation set purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "script_start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.plotly as py\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=True, world_readable=True, theme='ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = 12,8\n",
    "sns.set(rc={'figure.figsize':(20,12)})\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data path\n",
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b71624737b094f61d08a636414e77de6ea073c0"
   },
   "source": [
    "### 1. Load Data\n",
    "Reference: [](https://www.kaggle.com/badalgupta/simple-data-exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d3ce804f50e9450a193650e617541631da67abe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04 min: Start loading data\n",
      "Train No. of images: 1014544\n",
      "Test No. of images: 39706\n",
      "Validation No. of images: 9897\n",
      "0.16 min: Finish loading data\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data =================================================================\n",
    "print('%0.2f min: Start loading data'%((time.time() - script_start_time)/60))\n",
    "train={}\n",
    "test={}\n",
    "validation={}\n",
    "with open('%s/train.json'%(data_path)) as json_data:\n",
    "    train= json.load(json_data)\n",
    "with open('%s/test.json'%(data_path)) as json_data:\n",
    "    test= json.load(json_data)\n",
    "with open('%s/validation.json'%(data_path)) as json_data:\n",
    "    validation = json.load(json_data)\n",
    "\n",
    "print('Train No. of images: %d'%(len(train['images'])))\n",
    "print('Test No. of images: %d'%(len(test['images'])))\n",
    "print('Validation No. of images: %d'%(len(validation['images'])))\n",
    "\n",
    "# JSON TO PANDAS DATAFRAME\n",
    "# train data\n",
    "train_img_url=train['images']\n",
    "train_img_url=pd.DataFrame(train_img_url)\n",
    "train_ann=train['annotations']\n",
    "train_ann=pd.DataFrame(train_ann)\n",
    "train=pd.merge(train_img_url, train_ann, on='imageId', how='inner')\n",
    "\n",
    "# test data\n",
    "test=pd.DataFrame(test['images'])\n",
    "\n",
    "# Validation Data\n",
    "val_img_url=validation['images']\n",
    "val_img_url=pd.DataFrame(val_img_url)\n",
    "val_ann=validation['annotations']\n",
    "val_ann=pd.DataFrame(val_ann)\n",
    "validation=pd.merge(val_img_url, val_ann, on='imageId', how='inner')\n",
    "\n",
    "del (train_img_url, train_ann, val_img_url, val_ann)\n",
    "gc.collect()\n",
    "\n",
    "print('%0.2f min: Finish loading data'%((time.time() - script_start_time)/60))\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f7a8ca33d5d584a99ea623a3df5c59ed65f17ee"
   },
   "source": [
    "### 2. Check Data for Missing or Duplicated Values\n",
    "Findings:\n",
    "a. No missing values\n",
    "b. No duplicates in each data set, but val urls are from test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "84885b31648270bace3eeab62f8d1deb0fe755e9"
   },
   "outputs": [],
   "source": [
    "datas = {'Train': train, 'Test': test, 'Validation': validation}\n",
    "\n",
    "total_url = []\n",
    "dataset_url = {}\n",
    "for data_name, data in datas.items():\n",
    "    print('%s shape: %s'%(data_name, str(data.shape)))\n",
    "    print('%s Unique imageId: %s'%(data_name, len(data['imageId'].unique())))\n",
    "    print('%s Unique url: %s'%(data_name, len(data['url'].unique())))\n",
    "    print('%s NA: '%(data_name)) # No missing values\n",
    "    print(data.isnull().sum()) # No missing values\n",
    "    print('%s total unique url: %d'%(data_name, len(set(data['url'].tolist()))))\n",
    "    total_url = total_url + data['url'].tolist()\n",
    "    dataset_url[data_name] = data['url'].tolist()\n",
    "\n",
    "    print('-'*50)\n",
    "\n",
    "\n",
    "print('Total images: %d'%(len(total_url)))\n",
    "print('Total unique images: %d'%(len(set(total_url))))\n",
    "print('Duplicated url: %d'%(len(total_url) - len(set(total_url))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2fddf812105b69112fef7833b09b596a675684dd"
   },
   "source": [
    "9897? A bit familiar? Yes, same as the number of val rows. \n",
    "Still, let's create a grid to search for the duplicated the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3915a5f028261a310e21b5be5169de8e5d0f0215"
   },
   "outputs": [],
   "source": [
    "# Find the duplicated url\n",
    "from itertools import product\n",
    "combinations = list(product(*[datas.keys(), datas.keys()]))\n",
    "for comb in combinations:\n",
    "    print('%s inter %s: %d | %d'%(comb[0], comb[1], len(set(dataset_url[comb[0]])), len(set(dataset_url[comb[0]]).intersection(set(dataset_url[comb[1]])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53e07125e5945ff754b1e2de42c5fb7ca6151f78"
   },
   "source": [
    "'Test inter Validation: 39706 | 9897'\n",
    "What? Val is part of test?\n",
    "Let's confirm the duplicated url by merging test and val on url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c1a5a03494cfb71de18c276be9c731f83c719bc"
   },
   "outputs": [],
   "source": [
    "# Confirm the duplicated url\n",
    "test[['url']].merge(validation[['url']], how = 'inner').shape\n",
    "test_ = test.merge(validation[['url', 'labelId']], on = 'url',how = 'left')\n",
    "print('%s NA: '%('Test')) # No missing values\n",
    "print(test_.isnull().sum() / test_.isnull().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "295e4283f0c076cca2dac5f8d148d91a338d05ae"
   },
   "source": [
    "Let's which part of test are leaked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4ce0e6344b82999940ae4a2c2e86145bd4f9845"
   },
   "outputs": [],
   "source": [
    "# Plot imageId of of leaked lable\n",
    "test_leaked_lableId = test_[~pd.isna(test_['labelId'])]\n",
    "test_unleaked_lableId = test_[pd.isna(test_['labelId'])]\n",
    "number_of_known_lableId = validation.shape[0]\n",
    "plt.plot(test_leaked_lableId['imageId'], '.')\n",
    "plt.plot(test_unleaked_lableId['imageId'], '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fb473aa20f4e8bb603a31a43667f93b97008b2a"
   },
   "source": [
    "Display images to confirm again the leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da32f54e00b5c27e426db6aca81971342a72b52b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def display_category(urls, category_name):\n",
    "    img_style = \"width: 180px; margin: 0px; float: left; border: 1px solid black;\"\n",
    "    images_list = ''.join([f\"<img style='{img_style}' src='{u}' />\" for _, u in urls.head(12).iteritems()])\n",
    "    display(HTML(images_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ed6e017a26fb7b5e715a3bf1fc52fd99eb7f397"
   },
   "outputs": [],
   "source": [
    "#test data Images\n",
    "urls = test['url'][1:5]\n",
    "display_category(urls, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd26ce25803a6ffc960214c4ef13214806749c5e"
   },
   "outputs": [],
   "source": [
    "#validation Images\n",
    "urls = validation['url'][1:5]\n",
    "display_category(urls, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0c0b42f9f8e427836f1c214024c515617752def"
   },
   "outputs": [],
   "source": [
    "#train_data Images\n",
    "urls = train['url'][1:5]\n",
    "display_category(urls, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "36d9ea74ef5ed33ac644a0932dff09958397dd64"
   },
   "source": [
    "Now, we are 100% sure that the first 9897 of test set has their label id in val."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
