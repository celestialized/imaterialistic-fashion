{"cells":[{"metadata":{"_uuid":"c38e9ac774b6266ac7bb6f2b3ba8655fda030823","_cell_guid":"30662607-432a-498d-8c1e-b3c235aefd94"},"cell_type":"markdown","source":"# Overview\nInput: training data with image urls and labels\n\nGoal: generate the prediction of labels of each test set image\n\n# Key steps of my strategy\n1.\tRank the google labels of training images by frequency. Filter out labels that are not indicative or not having strong correlation with wish.com labels. \n2.\tFor each google label, extract all training images containing that label and corresponding wish.com labels. Aggregate those wish.com labels and rank them according to frequency. Filter out labels with frequency less than a certain threshold. My hypothesis is that the frequent wish.com labels are correlated with google label, so we can use google labels as an indicator of wish.com labels. \n3.\tDetect the google labels of each test image, and assign corresponding wish.com to each test image.\n4.\tCluster training images, and extract frequent labels of each cluster. My hypothesis is that for images in each cluster, they should have some labels in common.\n5.\tUse google labels to detect which cluster each test image belongs to. Add common labels of that cluster to the test image.\n6.\tRemove duplicate wish.com labels of each test image.\n\n\n# Full strategy with details:\n1.\tUse Google Vision API to detect the labels of 10,000 images in training set. Aggregate all labels together and rank them by frequency. Filter out top 10 most frequent labels as they are not indicative in this circumstance. Also, filter out labels with frequency less than a threshold. I will name the table generated in this step as “ranking table”.\n\n2.\tFor each label in “ranking table”, identify training images containing that label, and aggregate corresponding wish.com labels together. Then aggregate those wish.com labels and rank them according to frequency. Filter out wish.com labels with frequency lower than a threshold. My hypothesis is that the frequent wish.com labels are correlated with google label, so we can use google labels as an indicator of wish.com labels. After this step, a table indicating the matching relationship will be generated, and I will name this table as “matching table”.\n\n3.\tUse Google Vision API to detect the labels of each image in test set. For each Google label of the image, append the matching wish.com labels from the matching table. After this step, a table named “prediction table” will be generated. The column “predicted labels” is super long and there are many duplicate labels, I will remove duplicate labels later.\n\n4.\tUse k-means clustering method to assign 10,000 training set images into 60 clusters. For each cluster, select training set images belonging to that cluster and aggregate all corresponding wish.com labels. Rank those labels by frequency and select top 5 most frequent labels as representative labels of that cluster. After this step, a table indicating the representative labels of each cluster will be generated, and I will name this table as “clusters table”.\n\n5.\tFor each test set image, identify which cluster it belongs to. For each test set image, if predicted labels contain three or more representative labels of a cluster, then I would say the image belongs to that cluster, and I will assign other representative labels to that label. \n\n6.\tRemove duplicate labels of each test set image, as I found that duplicate labels will affect the f-score of prediction.\n\n# Flow chart\n![flow chart](https://pbs.twimg.com/media/DdCgJNZWkAA8eIw.jpg)"},{"metadata":{"_uuid":"2ed1dd3cd86aac858688b891c19aa3217db1320b","_cell_guid":"78ba4e3a-cc8c-4486-bf7f-e8a730d41ebc"},"cell_type":"markdown","source":"# About Google Vision API\n\nGoogle Vision API will analyze the image and returns the labels of that image, please look at my Github repo for example: https://github.com/DisenWang/Google_vision_api_example\n\nIt took a long time to analyze all images using Vision API, to save your time, I will upload the result as a dataset."},{"metadata":{"collapsed":true,"_uuid":"f30790d2cde59bc747c5f9199748d422d2da535f","_cell_guid":"8bd3706e-fbef-4dbf-b694-845a94a13135","trusted":false},"cell_type":"code","source":"# Pandas for managing datasets\nimport pandas as pd\n\n# Matplotlib for additional customization\nfrom matplotlib import pyplot as plt\n\nimport numpy as np\n# Seaborn for plotting and styling\nimport seaborn as sns\n\n\nimport datetime \nfrom collections import Counter\nimport re\nfrom plotly.offline import init_notebook_mode, iplot\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nfrom plotly import tools\nimport seaborn as sns\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80a124410111f7bb3f52553ba003e42994b8ce07","_cell_guid":"f20f9022-6b8e-4ae3-bed2-c251e7756e8e"},"cell_type":"markdown","source":"# Step 1. Rank Google labels\nUse Google Vision API to detect the labels of 10,000 images in training set. Aggregate all labels together and rank them by frequency. Filter out top 10 most frequent labels as they are not indicative in this circumstance. "},{"metadata":{"_uuid":"57775ec412a3980c7aa139d484e9e2858ab915ee","_cell_guid":"6118b0b5-e2f2-48e2-bc1f-1009e5605b61","trusted":false,"collapsed":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))\ndf = pd.read_csv('../input/train-labels/train_labels.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8cea9e26a5bc250d0e2017e1539270132e8cf4e1","_cell_guid":"fe6e0d06-33e2-4197-b579-d0469391a0be","trusted":false},"cell_type":"code","source":"# remove [ and ] from label lists\ndf['labels'] = df['labels'].str[1:]\ndf['labels'] = df['labels'].str[:-1]\ndf['labels'] = df['labels'] + ','","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cf65e0596a3ed9f94cd7442eeace3f39610ae60","_cell_guid":"1d9734e9-4728-4e6c-8691-f2f509fc4ddc"},"cell_type":"markdown","source":"Here I count and extract top 200 most frequent labels"},{"metadata":{"collapsed":true,"_uuid":"84c007ce844c0ba9f22d03911fce34c2b10e7058","_cell_guid":"7ffa7b86-d54a-4a2c-ba45-78aa6525b888","trusted":false},"cell_type":"code","source":"df_count = Counter(\" \".join(df[\"labels\"]).split(',')).most_common(200)\nall_label_count = pd.DataFrame(df_count)\nall_label_count.columns = ['label','count']\nall_label_count['percentage'] = all_label_count['count']/len(df.index)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"c04578e19b4b89f1466142478c441c7e24adf7e0","_cell_guid":"83c51c54-dd31-4aa5-90ea-170f1e520675","trusted":false,"collapsed":true},"cell_type":"code","source":"print (all_label_count.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05705b0c7959a7305ed3ae6ec401e50b0f0aaf83","_cell_guid":"175128ae-1b15-401a-adc7-d89ac518f29d"},"cell_type":"markdown","source":"Here I read in the training set, test set and validation set"},{"metadata":{"scrolled":true,"_uuid":"6f350d6456fc601c75fa3b85801be6879aa3f5bb","_cell_guid":"2389b35f-e53d-4ed5-a115-d482216c1a66","trusted":false,"collapsed":true},"cell_type":"code","source":"\nimport time\nscript_start_time = time.time()\n\nimport pandas as pd\nimport numpy as np\nimport json\nimport gc\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport plotly.plotly as py\nimport cufflinks as cf\ncf.set_config_file(offline=True, world_readable=True, theme='ggplot')\nplt.rcParams[\"figure.figsize\"] = 12,8\nsns.set(rc={'figure.figsize':(20,12)})\nplt.style.use('fivethirtyeight')\n\npd.set_option('display.max_rows', 600)\npd.set_option('display.max_columns', 50)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Data path\ndata_path = '.'\n\n# 1. Load data =================================================================\nprint('%0.2f min: Start loading data'%((time.time() - script_start_time)/60))\ntrain={}\ntest={}\nvalidation={}\nwith open('../input/imaterialist-challenge-fashion-2018/train.json',encoding='utf-8') as json_data:\n    train= json.load(json_data)\nwith open('../input/imaterialist-challenge-fashion-2018/test.json',encoding='utf-8') as json_data:\n    test= json.load(json_data)\nwith open('../input/imaterialist-challenge-fashion-2018/validation.json',encoding='utf-8') as json_data:\n    validation = json.load(json_data)\n\nprint('Train No. of images: %d'%(len(train['images'])))\nprint('Test No. of images: %d'%(len(test['images'])))\nprint('Validation No. of images: %d'%(len(validation['images'])))\n\n# JSON TO PANDAS DATAFRAME\n# train data\ntrain_img_url=train['images']\ntrain_img_url=pd.DataFrame(train_img_url)\ntrain_ann=train['annotations']\ntrain_ann=pd.DataFrame(train_ann)\ntrain=pd.merge(train_img_url, train_ann, on='imageId', how='inner')\n\n# test data\ntest=pd.DataFrame(test['images'])\n\n# Validation Data\nval_img_url=validation['images']\nval_img_url=pd.DataFrame(val_img_url)\nval_ann=validation['annotations']\nval_ann=pd.DataFrame(val_ann)\nvalidation=pd.merge(val_img_url, val_ann, on='imageId', how='inner')\n\ndel (train_img_url, train_ann, val_img_url, val_ann)\ngc.collect()\n\nprint('%0.2f min: Finish loading data'%((time.time() - script_start_time)/60))\nprint('='*50)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"baa3c81f0e8e6502607dca4de92c573f67ce120b","_cell_guid":"fc8c1cc1-ba97-4a6b-8686-138a05b84c36"},"cell_type":"markdown","source":"The index of training data start with 0, so I added 1 to all index for the merge operation later"},{"metadata":{"collapsed":true,"_uuid":"9eb905fe7acd24ec1d0103563e1d34ce74277f2b","_cell_guid":"f03cc4c8-76fc-42bd-a49a-411383ae874b","trusted":false},"cell_type":"code","source":"train.index += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c0a0a49befaafccf0c25960e29227dfca25ce70","_cell_guid":"22cb40a1-17fa-4697-806f-9e55ec157072"},"cell_type":"markdown","source":"# Step 2. Find Correlated Labels\nHere I defined a function named \"match_labels\", it is used to find the matched wish.com labels of each google label."},{"metadata":{"collapsed":true,"_uuid":"d2df03c324aaa79005656a1d2870ff898c67e757","_cell_guid":"f77dd897-1d94-4128-9136-a89d52c51c9e","trusted":false},"cell_type":"code","source":"def match_labels(google_label):\n    t=df[df['labels'].str.contains(google_label)]\n    safe2 = pd.merge(t, train, left_index = True, right_index = True)\n    l = []\n    for index, row in safe2.iterrows():\n        for i in row['labelId']:\n            l.append(i)\n    df_count2 = Counter(\"\".join(str(l)).split(','))\n    for key, cnts in list(df_count2.items()):   # list is important here\n        if cnts < 0.05*len(l):\n            del df_count2[key]\n\n    #print (df_count2)\n    tem = []\n    for i in df_count2:\n        tem.append(re.findall(r'\\d+',i))\n    #for i in tem:\n     #   print (i[0])\n\n    #for i in tem:\n     #   for n in top_labels:\n      #          if n == i[0]:\n       #             tem.remove(i)\n\n    final = []\n    for i in tem:\n        final.append(i[0])\n    #print (final)\n    return (final)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"537c0b64b473bfebe418de7b38e89f14b65abb67","_cell_guid":"8c815cc6-efbc-4f9f-b254-9d2390ff2d67"},"cell_type":"markdown","source":"I dropped out the top 10 most frequent google labels as they are too common and not indicative enough in this case"},{"metadata":{"collapsed":true,"_uuid":"3eb79575cc2a8bf26d9f36e5adf4d282ee8c12bd","_cell_guid":"c28de350-f389-4ffc-896b-5dc1dd15814c","trusted":false},"cell_type":"code","source":"all_label_count2 = all_label_count.iloc[10:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"945b5b08e17cfdb4412a325bd741d1b10399f896","_cell_guid":"fc6a26b2-3a25-42dc-a17a-ff5a73923128","trusted":false,"collapsed":true},"cell_type":"code","source":"print (all_label_count2.head())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3a98c5f4469b7c9b7188a2ef0b6cdd58b891317b","_cell_guid":"790b3508-6492-4254-89e5-328f73cf0579","trusted":false},"cell_type":"code","source":"all_label_count2['matched']=''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca7312beabbc037dcabf7db1b1154cc2c2cfa09f","_cell_guid":"80f8bf9c-79d8-429e-aea3-31cf799246dd"},"cell_type":"markdown","source":"Here for each google label, I'm trying to find out the wish.com labels that has correlation with it."},{"metadata":{"scrolled":true,"_uuid":"824740a9a8b8ace95b13d0866c1565860db2949a","_cell_guid":"46f4e91b-87b5-46c4-82c1-962439f83061","trusted":false,"collapsed":true},"cell_type":"code","source":"for index, row in all_label_count2.iterrows():\n    all_label_count2.set_value(index, 'matched', match_labels(row['label']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"474c9943e41d2afc32c8f54f5310dbdb6a8c3c6d","_cell_guid":"45e38c5c-db9a-490a-af5b-135e69dea9ee","trusted":false,"collapsed":true},"cell_type":"code","source":"print (all_label_count2.head())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"745c4975b01d2fa454e5f9c1bc131ff06d49a8ea","_cell_guid":"1a466e6a-1d55-4f1b-82bd-6ebc4444cf45","trusted":false},"cell_type":"code","source":"# remove [ and ] from label lists\nall_label_count2['matched'] = all_label_count2['matched'].astype(str)\nall_label_count2['matched'] = all_label_count2['matched'].str[1:]\nall_label_count2['matched'] = all_label_count2['matched'].str[:-1]\nall_label_count2['matched'] = all_label_count2['matched'] + ','","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"7b257a884cfc72ee2f27960bc27d24a46ff76142","_cell_guid":"5b59dea3-c8b7-460a-a7bd-44cdc496f7bc","trusted":false,"collapsed":true},"cell_type":"code","source":"print (all_label_count2.head())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d957a1db2c824f7c7344a7b2257690567254c4fc","_cell_guid":"cbb40d9c-cfb3-4d61-8a9d-dc5c92531564","trusted":false},"cell_type":"code","source":"all_label_count2['matched'] = all_label_count2['matched'].astype(str)\nall_label_count2['matched'] = all_label_count2['matched'].map(lambda x: ''.join([i for i in x if i.isdigit() or i.isspace()]))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"69a150a8a52d5b307dcf97f1ed1c8e67005ce3e1","_cell_guid":"21079b52-8f79-43c5-9174-67b72ea14800","trusted":false},"cell_type":"code","source":"all_label_count2['matched'] = all_label_count2['matched'] + ' '","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"a263651dc82262194159f530d7c4ada1ee1f954e","_cell_guid":"b8d03c0f-7e58-480a-a7c3-615e9623465e","trusted":false,"collapsed":true},"cell_type":"code","source":"print (all_label_count2['matched'].head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca6a1ea317233c35cdef23f82b71361ba2c601d4","_cell_guid":"d25b52e7-1905-4172-9176-9bc07437eb62"},"cell_type":"markdown","source":"# Step 3. Detect test images\nIn the \"labeled_test\" dataset are the labels detected by Google api for each image in test set"},{"metadata":{"collapsed":true,"scrolled":true,"_uuid":"ac0cee4f36d0c252152c05f64f24d68b302f3113","_cell_guid":"9155fb98-5d40-4d7e-a271-636626d7cedc","trusted":false},"cell_type":"code","source":"test = pd.read_csv('../input/labeled-test/labeled_test.csv', index_col=0,encoding = \"ISO-8859-1\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"scrolled":true,"_uuid":"438f6b6d492e03891124d08404f1d82591a2c1c0","_cell_guid":"c6581d9b-b083-4689-bedb-b69a9a63f792","trusted":false},"cell_type":"code","source":"test['labels'] = test['labels'].str[1:]\ntest['labels'] = test['labels'].str[:-1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c134ee99c7fb653f9ad3ebc0415e2be4adb3e6ab","_cell_guid":"c08e499c-700f-4393-b97a-33910e0f38da","trusted":false,"collapsed":true},"cell_type":"code","source":"print (test.head())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"4da8c8176d5aef570e976086d200784cf07bca70","_cell_guid":"2215fa92-e5f0-43c3-97cf-85b5c0930821","trusted":false},"cell_type":"code","source":"test['prediction'] = ''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"637026aa4fd3b4b52ef6d6ed1aa6e5f1eb3e1ccb","_cell_guid":"0ad926eb-3054-4375-b206-e9d2310335ac"},"cell_type":"markdown","source":"This step will take some time since there has nested loop. For each google label of each image, I add the corresponding wish.com labels extracted above."},{"metadata":{"collapsed":true,"_uuid":"08ec6c4d6b02ba1a356e73f68909715f2d91714b","_cell_guid":"071b2a5a-d78a-41b4-824a-c3e4752d4ed4","trusted":false},"cell_type":"code","source":"for index, trow in test.iterrows():\n    for index, arow in all_label_count2.iterrows():\n        if arow['label'] in trow['labels']:\n            trow['prediction']=trow['prediction']+arow['matched']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5274572b4dbffe3208bf3c489acc25b4d3b5fab","_cell_guid":"bce9178a-24f1-44a6-95cf-ca49e6e3ac97"},"cell_type":"markdown","source":"# Step 4. Clustering\n\nHere I'm trying to use k-means to cluster all wish.com labels. For k-means clustering, number of clusters is an input parameter. I used the Elbow Method (https://en.wikipedia.org/wiki/Elbow_method_(clustering)) and decided to set number of clusters as 60."},{"metadata":{"_uuid":"ff5ec90233617a9f18f0e6f9bc197c5316fdfc3e","_cell_guid":"8bbcd0a5-992c-48ab-adfc-16a77f4e1178","trusted":false,"collapsed":true},"cell_type":"code","source":"df = train.head(10000).drop(columns=['url'])\n# print (df['labelId'])\ndf['labelId'] = df['labelId'].astype(str)\n\n# Note that the result of this block takes a while to show\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#define vectorizer parameters\ntfidf_vectorizer = TfidfVectorizer( max_features=200000,\n                                  stop_words='english',\n                                 use_idf=True)\n\n%time tfidf_matrix = tfidf_vectorizer.fit_transform(df['labelId']) #fit the vectorizer to synopses\n\n\nprint(tfidf_matrix.shape)\nterms = tfidf_vectorizer.get_feature_names()\nlen(terms)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2955b5120f8b9f0d3d14f17d115224e5d0c13ca1","_cell_guid":"07fc5c19-966d-4323-906c-25d85bc8f37f","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nnum_clusters = 60\n\nkm = KMeans(n_clusters=num_clusters)\n\n%time km.fit(tfidf_matrix)\n\nclusters = km.labels_.tolist()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49448b221b1960dbdb49fa671795eeeefc01bbe0","_cell_guid":"b3d9fbac-d18d-48f8-9425-5f3720264d6a","trusted":false,"collapsed":true},"cell_type":"code","source":"df = train.head(10000).drop(columns=['url'])\n\ndf_cluster = pd.DataFrame(clusters)\ndf_cluster.columns = [\"cluster\"]\nprint (df_cluster.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a79a94edf9fe2285143bc4f7b23b2b4927756e5","_cell_guid":"96983edf-916b-4a57-8aee-913af2fbc3a0","trusted":false,"collapsed":true},"cell_type":"code","source":"df = pd.merge(df, df_cluster, left_index = True, right_index = True)\n\ndf.index += 1\n\ntrain_labels = pd.read_csv('../input/train-labels/train_labels.csv', index_col=0)\n\nprint (train_labels.head())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a66331d4e71c306822aaeeeff1145b8e06ffd032","_cell_guid":"5bf4b3ad-7d63-4bac-8bb5-322fbed57487","trusted":false},"cell_type":"code","source":"df = pd.merge(df, train_labels, left_index = True, right_index = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85487cd09aae088f807126b12c708ed3ca4f5233","_cell_guid":"213a8dde-c342-42b2-b386-d0fa818d3024","trusted":false,"collapsed":true},"cell_type":"code","source":"df['labels'] = df['labels'].str[1:]\ndf['labels'] = df['labels'].str[:-1]\ndf['labels'] = df['labels'] + ','\nprint (df.head())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"6716c0024c28e852d544c019ba49fc5293a93b36","_cell_guid":"30084184-7e82-4ade-937a-b0c13ee16682","trusted":false,"collapsed":true},"cell_type":"code","source":"x = df.groupby('cluster')['labels'].apply(lambda x: x.sum())\n\nx.columns = [\"labels\", \"frequent_labels\"]\n\nx = x.to_frame()\n\nx.columns = [\"labels\"]\nx['frequent_labels']=\"\"\nx['labels'] = x['labels'].astype(str).replace(\"''\", \"\")\nprint (x.head())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"06b866e2edacbf70cc753d690940893964f1f865","_cell_guid":"2e86fb25-2379-4b09-8ecf-0a221397ae7d","trusted":false},"cell_type":"code","source":"from collections import Counter\nfor index, row in x.iterrows():\n    df_count = Counter(\"\".join(row['labels']).split(',')).most_common(5)\n    l = []\n    for i in df_count:\n        l.append(i[0])\n    row['frequent_labels']=l","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"0cc2c8f7ca36137e56e04910f5d66f687f9b4a8c","_cell_guid":"c3bd89fb-6a45-4236-8509-1164477a3a13","trusted":false},"cell_type":"code","source":"y = df.groupby('cluster')['labelId'].apply(lambda x: x.sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51b0bdcf1ccd2955199dfba8054f9408ff302090","_cell_guid":"4622550e-0465-45d2-88aa-1b461f53c203","trusted":false,"collapsed":true},"cell_type":"code","source":"y = y.to_frame()\ny.columns = [\"wish_labels\"]\ny['frequent_wish_labels']=\"\"\n\nprint (y.head())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"fdb42c8c8933e9cd5ac7aed1519c2d9bdd1b9c1a","_cell_guid":"47956841-dfbe-4805-9916-64630f46fc61","trusted":false},"cell_type":"code","source":"for index, row in y.iterrows():\n    df_count = Counter(\",\".join(row['wish_labels']).split(',')).most_common(10)\n    l = []\n    for i in df_count:\n        l.append(i[0])\n    row['frequent_wish_labels']=l","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"c35eb7cb9ae54b116a89d20b168e694b13454298","_cell_guid":"abd5d5b5-7395-411e-823e-b7e4046f71ba","trusted":false},"cell_type":"code","source":"cluster_train = pd.concat([x,y],axis=1)\ncluster_train= cluster_train[['frequent_labels','frequent_wish_labels']]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"ba74c7d9060c8921776e5f304247eea94f19b621","_cell_guid":"418f5eef-fbdc-4ff2-9bc7-6a1c63b9e4ff","trusted":false},"cell_type":"code","source":"cluster_add = cluster_train","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"15fe701bc6704b18569aff11f6f522ae8a08772d","_cell_guid":"ddf21afd-7c02-450a-a4b4-f47b154cd387","trusted":false},"cell_type":"code","source":"cluster_add['frequent_wish_labels'] = cluster_add['frequent_wish_labels'].astype(str)\ncluster_add['frequent_wish_labels'] = cluster_add['frequent_wish_labels'].map(lambda x: ''.join([i for i in x if i.isdigit() or i.isspace()]))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"898429853bf827498ce3244053a6aa809d7c2fea","_cell_guid":"b3000715-747e-4d3e-974a-ab080b0d451b","trusted":false},"cell_type":"code","source":"test['cluster'] = \"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a243de8f96679f3635fc380107dda2643c4ae9a","_cell_guid":"287d9262-1ee1-4077-8ebb-8f1ae1f6f9f6"},"cell_type":"markdown","source":"# Step 5. Add cluster labels\nHere I add the cluster labels to previous predictions. How do I determine which cluster each image belongs to? I used the frequent labels of each cluster. For each image, if it contains at least 5 frequent labels in a cluster, then I would determine that image belongs to the cluster and add corresponding labels to that images. Please note that I didn't require each image only belong to one cluster, so it is possible that a image belongs to multiple clusters"},{"metadata":{"collapsed":true,"_uuid":"b0638ff8393b0f38895dc230731378a8bf3059a7","_cell_guid":"e9e9b181-a9b2-4199-9630-04623ca89cb6","trusted":false},"cell_type":"code","source":"for index, row in test.iterrows():\n    x = 0\n    for cdex,crow in cluster_train.iterrows():\n        for n in crow['frequent_wish_labels']:\n            n = str(n)\n            \n            if n in str(row['prediction']):\n                x +=1\n    if x >= 5:\n        test.set_value(index, 'cluster', str(row['prediction']) +\" \" + str(cluster_add.at[cdex,'frequent_wish_labels']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32587506b0adcef378bf7ef83d54818b52ee9228","_cell_guid":"b065490b-a0f0-4a7e-a564-1b97e24b52be"},"cell_type":"markdown","source":"# Step 6. Remove duplicate labels\nIn previous steps I added labels from matching and clustering together, and there are some duplicate labels. In Kaggle's evaluation system there seems to have penalty for duplicate labels, so I will remove them and make sure each unique label only appears once for each image."},{"metadata":{"collapsed":true,"_uuid":"e98948db16ea3ae9409d86eeff6dc906f64494eb","_cell_guid":"29142e02-d4a8-4e2a-b11e-780949119628","trusted":false},"cell_type":"code","source":"for index, row in test.iterrows():\n    row['cluster'] = row['cluster'].split(\" \")\n    test.set_value(index, 'cluster', set(row['cluster']))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"80fc67357ff7da103a952779d311d9ab833c9f3b","_cell_guid":"48cc673b-81fa-48b2-b286-48c53685e7f8","trusted":false},"cell_type":"code","source":"test['cluster'] = test['cluster'].astype(str)\ntest['cluster'] = test['cluster'].str[1:]\ntest['cluster'] = test['cluster'].str[:-1]\ntest['cluster'] = test['cluster'] + ','\ntest['cluster'] = test['cluster'].map(lambda x: ''.join([i for i in x if i.isdigit() or i.isspace()]))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"75030e0bc7ad8003a8f32924a5efb3ced9fed278","_cell_guid":"8e3bd88d-bd02-4085-8994-a7995e4a29e2","trusted":false},"cell_type":"code","source":"print (test['cluster'].head())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"34bbb66a633a74cd4b533313a502ce31ed0704b9","_cell_guid":"fa294f95-6ce2-443e-9d06-91f5ebac4f45","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}